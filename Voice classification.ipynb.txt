{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c705ed80b60bd6a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:46:26.301604300Z",
     "start_time": "2024-01-22T16:46:26.227551800Z"
    },
    "execution": {
     "iopub.execute_input": "2023-12-25T19:12:09.582707Z",
     "iopub.status.busy": "2023-12-25T19:12:09.581818Z",
     "iopub.status.idle": "2023-12-25T19:12:11.504557Z",
     "shell.execute_reply": "2023-12-25T19:12:11.503594Z",
     "shell.execute_reply.started": "2023-12-25T19:12:09.582658Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43ec107cff629c01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:46:26.311104600Z",
     "start_time": "2024-01-22T16:46:26.295192Z"
    },
    "execution": {
     "iopub.execute_input": "2023-12-25T19:25:20.844032Z",
     "iopub.status.busy": "2023-12-25T19:25:20.843492Z",
     "iopub.status.idle": "2023-12-25T19:25:20.933773Z",
     "shell.execute_reply": "2023-12-25T19:25:20.932649Z",
     "shell.execute_reply.started": "2023-12-25T19:25:20.843992Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def split_data(data_dir, output_dir, size):\n",
    "    print(f'Splitting {size * 100}% test {100-size *100}% training...')\n",
    "    train_dir = os.path.join(output_dir, \"Train\")\n",
    "    test_dir = os.path.join(output_dir, \"Test\")\n",
    "    if os.path.exists(output_dir):\n",
    "        shutil.rmtree(output_dir)\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "    for folder in os.listdir(data_dir):\n",
    "        folder_path = os.path.join(data_dir, folder)\n",
    "        audio_files = os.listdir(folder_path)\n",
    "        random.shuffle(audio_files)\n",
    "        split_index = int(size * len(audio_files))\n",
    "        os.makedirs(os.path.join(train_dir, folder), exist_ok=True)\n",
    "        os.makedirs(os.path.join(test_dir, folder), exist_ok=True)\n",
    "        for file in audio_files[:split_index]:\n",
    "            destination_path = os.path.join(test_dir, folder, file)\n",
    "            shutil.copy(os.path.join(folder_path, file), destination_path)\n",
    "\n",
    "        for file in audio_files[split_index:]:\n",
    "            destination_path = os.path.join(train_dir, folder, file)\n",
    "            shutil.copy(os.path.join(folder_path, file), destination_path)\n",
    "    print(f'{size * 100}% test {100-size *100}% training done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95b6ef8f638cfb37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:46:43.950533400Z",
     "start_time": "2024-01-22T16:46:26.304595900Z"
    },
    "execution": {
     "iopub.execute_input": "2023-12-25T19:25:23.933903Z",
     "iopub.status.busy": "2023-12-25T19:25:23.933246Z",
     "iopub.status.idle": "2023-12-25T19:25:27.580140Z",
     "shell.execute_reply": "2023-12-25T19:25:27.579474Z",
     "shell.execute_reply.started": "2023-12-25T19:25:23.933871Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting 20.0% test 80.0% training...\n",
      "20.0% test 80.0% training done\n",
      "Splitting 30.0% test 70.0% training...\n",
      "30.0% test 70.0% training done\n",
      "Splitting 40.0% test 60.0% training...\n",
      "40.0% test 60.0% training done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Data_split2_20%_80%', 'Data_split2_30%_70%', 'Data_split2_40%_60%']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from decimal import Decimal\n",
    "\n",
    "data_dir = \"10 - Data\"\n",
    "size = Decimal('0.2')\n",
    "Out = []\n",
    "while size <= Decimal('0.4'):\n",
    "    output_dir = \"Data_split2_\"+str(int(size*100))+'%_'+str(int(100-size*100))+'%'\n",
    "    Out.append(output_dir)\n",
    "    split_data(data_dir,output_dir,size)\n",
    "    size = size + Decimal('0.1')\n",
    "Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3435d67b3d543f06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:46:43.966909900Z",
     "start_time": "2024-01-22T16:46:43.948538300Z"
    },
    "execution": {
     "iopub.execute_input": "2023-12-25T20:18:12.017469Z",
     "iopub.status.busy": "2023-12-25T20:18:12.016930Z",
     "iopub.status.idle": "2023-12-25T20:18:12.025870Z",
     "shell.execute_reply": "2023-12-25T20:18:12.024612Z",
     "shell.execute_reply.started": "2023-12-25T20:18:12.017429Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def features_extractor2(file):\n",
    "    audio, sample_rate = librosa.load(file)\n",
    "\n",
    "    # MFCCs\n",
    "    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "    \n",
    "    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "\n",
    "    # Chroma\n",
    "    chroma_features = librosa.feature.chroma_stft(y=audio, sr=sample_rate)\n",
    "  \n",
    "    chroma_scaled_features = np.mean(chroma_features.T,axis=0)\n",
    "\n",
    "    # Mel\n",
    "    mel_features = librosa.feature.melspectrogram(y=audio, sr=sample_rate)\n",
    "    \n",
    "    mel_scaled_features = np.mean(mel_features.T,axis=0)\n",
    "\n",
    "    # Contrast\n",
    "    contrast_features = librosa.feature.spectral_contrast(y=audio, sr=sample_rate)\n",
    "    \n",
    "    contrast_scaled_features = np.mean(contrast_features.T,axis=0)\n",
    "\n",
    "    # Tonnetz\n",
    "    tonnetz_features = librosa.feature.tonnetz(y=audio, sr=sample_rate)\n",
    "   \n",
    "    tonnetz_scaled_features = np.mean(tonnetz_features.T,axis=0)\n",
    "\n",
    "    # Additional feature extraction code as needed\n",
    "\n",
    "    return mfccs_scaled_features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87ea575f0cd0e8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:46:44.031625600Z",
     "start_time": "2024-01-22T16:46:43.967907100Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-12-25T19:58:43.332324Z",
     "iopub.status.busy": "2023-12-25T19:58:43.331782Z",
     "iopub.status.idle": "2023-12-25T19:58:43.340797Z",
     "shell.execute_reply": "2023-12-25T19:58:43.339931Z",
     "shell.execute_reply.started": "2023-12-25T19:58:43.332261Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def parse_audio_files(parent_dir, file_ext='*.wav'):\n",
    "    sub_dirs = os.listdir(parent_dir)\n",
    "    sub_dirs.sort()\n",
    "    features, labels = np.empty((0, 40)), np.empty(0)\n",
    "\n",
    "    for label, sub_dir in enumerate(sub_dirs):\n",
    "        print(\"Extracting \" + sub_dir + \" features  ...\")\n",
    "\n",
    "        for fn in glob(os.path.join(parent_dir, sub_dir, file_ext)):\n",
    "            try:\n",
    "                mfccs  = features_extractor2(fn)\n",
    "            except Exception as e:\n",
    "                print(\"[Error] extract feature error in %s. %s\" % (fn, e))\n",
    "                continue\n",
    "            ##ex_features = np.hstack([mfccs , mel ])\n",
    "            features = np.vstack([features, mfccs ])\n",
    "            labels = np.append(labels, label)\n",
    "\n",
    "        print(\"Extracting %s features done\" % sub_dir)\n",
    "\n",
    "    return np.array(features), np.array(labels, dtype=int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102ad792f8af1d6e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-22T16:46:45.358238900Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "def Trainingg(train_directory,test_directory):\n",
    "    train_features , train_labels =parse_audio_files(train_directory)\n",
    "    test_features , test_labels =parse_audio_files(test_directory)\n",
    "   \n",
    "\n",
    "    params = {'activation': 'relu', 'batch_size': 32, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'max_iter': 200, 'random_state': 1, 'solver': 'sgd'}\n",
    "\n",
    "    clf = MLPClassifier(**params)\n",
    "    clf.fit(X_train_scaled, Y_train)\n",
    "    Y_pred=clf.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(Y_test, Y_pred)\n",
    "    conf_matrix = confusion_matrix(Y_test, Y_pred)\n",
    "    return accuracy, conf_matrix\n",
    "accuracies = []\n",
    "for d in Out:\n",
    "    d_train = d + '/Train'\n",
    "    d_test  = d + '/Test'\n",
    "    print(d)\n",
    "    accuracyy, conf_matrix = Trainingg(d_train,d_test)\n",
    "    accuracies.append(accuracyy)\n",
    "    print(\"accuracy for \" + d[11:] + \" is \" + str(accuracyy))\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Dog','Rooster', 'Pig' , 'Cow' ,'Frog' ], yticklabels=['Dog','Rooster', 'Pig' , 'Cow' ,'Frog' ])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b536117cf62b41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:46:45.378186900Z",
     "start_time": "2024-01-22T16:46:45.363225600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "def find_best_params(X_train, y_train, X_test, y_test):\n",
    "    models={\n",
    "        \n",
    "        'NN':{\n",
    "            'model': MLPClassifier(),\n",
    "            'params' : {\n",
    "              'hidden_layer_sizes': [(100,)],\n",
    "             'activation': ['relu'],\n",
    "               'solver': ['adam'],\n",
    "               'learning_rate': ['constant'],\n",
    "             'max_iter': [200],\n",
    "             'batch_size': [32],\n",
    "             'random_state' :[ 1]\n",
    "    }\n",
    "       },\n",
    "\n",
    "\n",
    "        'SVM':{\n",
    "            'model':svm.SVC(),\n",
    "            'params':{\n",
    "                'C':[1,10,20],\n",
    "                'kernel': ['linear'],\n",
    "            }\n",
    "        },\n",
    "    \n",
    "\n",
    "\n",
    "        'Random_Forest': {\n",
    "            'model': RandomForestClassifier(),\n",
    "            'params': {\n",
    "                'n_estimators': [10, 20,50],\n",
    "                'max_depth': [None, 10],\n",
    "\n",
    "            }\n",
    "        } ,\n",
    "\n",
    "        'KNN': {\n",
    "            'model': KNeighborsClassifier(),\n",
    "            'params': {\n",
    "                'n_neighbors': [3, 5, 7],\n",
    "\n",
    "            }\n",
    "        },\n",
    "\n",
    "    \n",
    "    \n",
    "    }\n",
    "\n",
    "    scores = []\n",
    "\n",
    "\n",
    "    \n",
    "    for algo , params in models.items():\n",
    "        grid_cv = GridSearchCV(params['model'],params['params'], cv=5, scoring='accuracy', return_train_score=False)\n",
    "        grid_cv.fit(X_train,Y_train)\n",
    "        best_model = grid_cv.best_estimator_\n",
    "        test_score = best_model.score(X_test, y_test) \n",
    "        scores.append({\n",
    "            'model_name': algo,\n",
    "            'best_score': test_score,\n",
    "            'best_params': grid_cv.best_params_\n",
    "\n",
    "        })\n",
    "        \n",
    "\n",
    "\n",
    "    scores_df = pd.DataFrame(scores,columns=['model_name','best_score','best_params'])\n",
    "    return scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8862eb57a4b4b2f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-22T16:46:45.370206800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_features , train_labels =parse_audio_files('Data_split2_30%_70%/Train')\n",
    "test_features , test_labels =parse_audio_files('Data_split2_30%_70%/Test')\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train =  train_features\n",
    "Y_train =  train_labels\n",
    "\n",
    "X_test =  test_features\n",
    "Y_test =  test_labels\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662d597dbed6bfa2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:46:45.381178800Z",
     "start_time": "2024-01-22T16:46:45.379183800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "find_best_params(X_train_scaled, Y_train, X_test_scaled, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd8b1b88755c0c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T16:46:45.408107Z",
     "start_time": "2024-01-22T16:46:45.385167900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model5 = RandomForestClassifier( max_depth= None,n_estimators= 50) \n",
    "model5.fit(X_train_scaled, Y_train)\n",
    "model5.score(X_test_scaled, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09672a36e96c81a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-22T16:46:45.395141800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mlp_params = {\n",
    "    'hidden_layer_sizes': (100,),\n",
    "    'activation': 'relu',\n",
    "    'solver': 'adam',\n",
    "    'learning_rate': 'constant',\n",
    "    'max_iter': 200,\n",
    "    'batch_size': 32,\n",
    "    'random_state': 1\n",
    "}\n",
    "\n",
    "# Create MLP classifier\n",
    "mlp_classifier = MLPClassifier(**mlp_params)\n",
    "mlp_classifier.fit(X_train_scaled, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa4ef1c106c20be",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-22T16:46:45.396139800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "Y_pred=mlp_classifier.predict(X_test_scaled)\n",
    "conf_matrix = confusion_matrix(Y_test, Y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['  Dog bark',\n",
    "                                                                         '  Rain',\n",
    "                                                                         ' Sea waves',\n",
    "                                                                         ' Baby cry',\n",
    "                                                                         ' Clock tick',\n",
    "                                                                         'Person sneeze',\n",
    "                                                                         'Helicopter',\n",
    "                                                                         'Chainsaw',\n",
    "                                                                         ' Rooster',\n",
    "                                                                         ' Fire crackling'], yticklabels=['  Dog bark',\n",
    "                                                                                                          '  Rain',\n",
    "                                                                                                          ' Sea waves',\n",
    "                                                                                                          ' Baby cry',\n",
    "                                                                                                          ' Clock tick',\n",
    "                                                                                                          'Person sneeze',\n",
    "                                                                                                          'Helicopter',\n",
    "                                                                                                          'Chainsaw',\n",
    "                                                                                                          ' Rooster',\n",
    "                                                                                                          ' Fire crackling'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df90dbfd60ac3860",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-22T16:46:45.399129800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "def find_best_mlp_params(X_train, y_train, X_test, y_test):\n",
    "    models={\n",
    "\n",
    "        'NN':{\n",
    "            'model': MLPClassifier(),\n",
    "            'params' : {\n",
    "                'hidden_layer_sizes': [(100,)],\n",
    "                'activation': ['relu', 'logistic'],\n",
    "                'solver': ['adam'],\n",
    "                'learning_rate': ['constant'],\n",
    "                'max_iter': [200],\n",
    "                'batch_size': ['auto', 32],\n",
    "                'random_state' :[ 1]\n",
    "            }\n",
    "        }\n",
    "\n",
    "    }\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    for algo , params in models.items():\n",
    "        grid_cv = GridSearchCV(params['model'],params['params'], cv=5, scoring='accuracy', return_train_score=False)\n",
    "        grid_cv.fit(X_train,Y_train)\n",
    "        best_model = grid_cv.best_estimator_\n",
    "        test_score = best_model.score(X_test, y_test)\n",
    "        scores.append({\n",
    "            'model_name': algo,\n",
    "            'best_score': test_score,\n",
    "            'best_params': grid_cv.best_params_\n",
    "\n",
    "        })\n",
    "\n",
    "    scores_df = pd.DataFrame(scores,columns=['model_name','best_score','best_params'])\n",
    "    return scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e89b31e8994a290",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-22T16:46:45.401124500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_features , train_labels =parse_audio_files('Data_split_30%_70%/Train')\n",
    "test_features , test_labels =parse_audio_files('Data_split_30%_70%/Test')\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train =  train_features\n",
    "Y_train =  train_labels\n",
    "\n",
    "X_test =  test_features\n",
    "Y_test =  test_labels\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7438cee5896282f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-22T16:46:45.402121900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "mlp_params = {\n",
    "    'activation': 'relu',\n",
    "    'batch_size': 32,\n",
    "    'hidden_layer_sizes': (100,),\n",
    "    'learning_rate': 'constant',\n",
    "    'max_iter': 200,\n",
    "    'random_state': 1,\n",
    "    'solver': 'adam'\n",
    "}\n",
    "\n",
    "params = {'activation': 'relu',\n",
    "          'batch_size': 'auto', \n",
    "          'hidden_layer_sizes': (100,)\n",
    "    , 'learning_rate': 'constant', \n",
    "          'max_iter': 200, \n",
    "          'random_state': 1,\n",
    "          'solver': 'adam'}\n",
    "\n",
    "\n",
    "\n",
    "model = MLPClassifier(**mlp_params)\n",
    "model.fit(X_train, Y_train )\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Generate and print the classification report\n",
    "report = classification_report(Y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8830807c79b71e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-22T16:46:45.406111700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "find_best_mlp_params(X_train_scaled,Y_train,X_test_scaled,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3759649f017cc613",
   "metadata": {
    "collapsed": false
   },
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4205679,
     "sourceId": 7257488,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
